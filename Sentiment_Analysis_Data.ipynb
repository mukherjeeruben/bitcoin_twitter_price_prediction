{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from datetime import datetime\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "sentiment_map = list()"
      ],
      "metadata": {
        "id": "xYM7qkewXP58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5076897-c801-444c-b060-b33dd88f2a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''For Year 2019'''\n",
        "entity = list()\n",
        "for index in range(1, 12):\n",
        "  item = dict()\n",
        "  if index == 4 or index == 6 or index == 9 or index == 11:\n",
        "    entity.append({'filename' :'df_tweet_file_data_' + str(index) + '.csv','month': index, 'days': 30})\n",
        "  elif index == 2:\n",
        "    entity.append({'filename' :'df_tweet_file_data_' + str(index) + '.csv','month': index, 'days': 28})\n",
        "  else:\n",
        "    entity.append({'filename' :'df_tweet_file_data_' + str(index) + '.csv','month': index, 'days': 31}) "
      ],
      "metadata": {
        "id": "bppq6lp0Hoo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df_crypto):\n",
        "  df_crypto['datetime'] =  pd.to_datetime(df_crypto['timestamp'], format='%Y-%m-%d %H:%M:%S+%f')\n",
        "  df_crypto['text'] = df_crypto['text'].astype(str).apply(lambda x: re.sub('[^a-zA-Z0-9]+', ' ', x).lower())\n",
        "  df_crypto['text'] = df_crypto['text'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "  df_crypto['sentiment'] = df_crypto['text'].apply(lambda x: TextBlob(x).sentiment[0])\n",
        "  return df_crypto[['datetime', 'sentiment']]"
      ],
      "metadata": {
        "id": "PxqngP6PGuYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg(hour_df) -> 'sentiment_average':\n",
        "  negative_count = [item for item in hour_df['sentiment'] if item < 0.0]\n",
        "  positive_count = [item for item in hour_df['sentiment'] if item > 0.0]\n",
        "  if len(negative_count) > len(positive_count):\n",
        "    average = sum(negative_count)/len(negative_count)\n",
        "    return average\n",
        "  else:\n",
        "    if len(positive_count) > 0:\n",
        "      average = sum(positive_count)/len(positive_count)\n",
        "      return average\n",
        "    else:\n",
        "      return 0"
      ],
      "metadata": {
        "id": "tPGngeJNbBst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "year = 2019\n",
        "hour_range = [item for item in range(0, 24)]\n",
        "for item in entity:\n",
        "  print('Processing for '+item['filename'])\n",
        "  df_raw = pd.read_csv('/content/drive/My Drive/Tweet_Data/df_tweet_data_2019/'+ item['filename'])\n",
        "  date_range = [item for item in range(1, item['days'] + 1)]\n",
        "  df_senti = preprocess(df_raw)\n",
        "  for date_stamp in date_range:\n",
        "    for hour_stamp in hour_range:\n",
        "      starttime = str(year) + '-' + str(item['month']) + '-' + str(date_stamp)+ ' ' +  str(hour_stamp) + ':00:00'\n",
        "      if hour_stamp == 23:\n",
        "        endtime = str(year) + '-' + str(item['month']) + '-' + str(date_stamp)+ ' ' + str(hour_stamp) + ':59:59'\n",
        "      else:\n",
        "        endtime = str(year) + '-' + str(item['month']) + '-' + str(date_stamp)+ ' ' +  str(hour_stamp + 1) + ':00:00'\n",
        "      start = datetime.strptime(starttime, '%Y-%m-%d %H:%M:%S')\n",
        "      end = datetime.strptime(endtime, '%Y-%m-%d %H:%M:%S')\n",
        "      mask = (df_senti['datetime'] >= start) & (df_senti['datetime'] < end)\n",
        "      date_range_df = df_senti.loc[mask]\n",
        "      avg_val = get_avg(date_range_df)\n",
        "      sentiment_map.append({'timestamp': end, 'sentiment':avg_val})\n",
        "\n",
        "final_df = pd.DataFrame(sentiment_map)\n",
        "final_df.to_csv('/content/drive/My Drive/CA683/tweet_2019_sentiment.csv', sep=',')"
      ],
      "metadata": {
        "id": "8XSiRD0r4aeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95f2bbc-5b36-421b-8539-8c6af53b624a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing for df_tweet_file_data_1.csv\n",
            "Processing for df_tweet_file_data_2.csv\n",
            "Processing for df_tweet_file_data_3.csv\n",
            "Processing for df_tweet_file_data_4.csv\n",
            "Processing for df_tweet_file_data_5.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing for df_tweet_file_data_6.csv\n",
            "Processing for df_tweet_file_data_7.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing for df_tweet_file_data_8.csv\n",
            "Processing for df_tweet_file_data_9.csv\n",
            "Processing for df_tweet_file_data_10.csv\n",
            "Processing for df_tweet_file_data_11.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''For years 2009 to 2018'''\n",
        "def monthentity():\n",
        "  entity = list()\n",
        "  for index in range(1, 13):\n",
        "    item = dict()\n",
        "    if index == 4 or index == 6 or index == 9 or index == 11:\n",
        "      entity.append({'month': index, 'days': 30})\n",
        "    elif index == 2:\n",
        "      entity.append({'month': index, 'days': 28})\n",
        "    else:\n",
        "      entity.append({'month': index, 'days': 31}) \n",
        "  return entity\n",
        "\n",
        "month_day = monthentity()"
      ],
      "metadata": {
        "id": "2YpJCiYdo6qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = [2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018] \n",
        "\n",
        "hour_range = [item for item in range(0, 24)]\n",
        "\n",
        "for year in years:\n",
        "  print('Processing for year '+ str(year))\n",
        "  df_raw = pd.read_csv('/content/drive/My Drive/Tweet_Data/df_tweet_file_data_'+ str(year) + '.csv')\n",
        "  df_senti = preprocess(df_raw)\n",
        "  for item in month_day:\n",
        "    date_range = [item for item in range(1, item['days'] + 1)]\n",
        "    for date_stamp in date_range:\n",
        "      for hour_stamp in hour_range:\n",
        "        starttime = str(year) + '-' + str(item['month']) + '-' + str(date_stamp)+ ' ' +  str(hour_stamp) + ':00:00'\n",
        "        if hour_stamp == 23:\n",
        "          endtime = str(year) + '-' + str(item['month']) + '-' + str(date_stamp)+ ' ' + str(hour_stamp) + ':59:59'\n",
        "        else:\n",
        "          endtime = str(year) + '-' + str(item['month']) + '-' + str(date_stamp)+ ' ' +  str(hour_stamp + 1) + ':00:00'\n",
        "        start = datetime.strptime(starttime, '%Y-%m-%d %H:%M:%S')\n",
        "        end = datetime.strptime(endtime, '%Y-%m-%d %H:%M:%S')\n",
        "        mask = (df_senti['datetime'] >= start) & (df_senti['datetime'] < end)\n",
        "        date_range_df = df_senti.loc[mask]\n",
        "        avg_val = get_avg(date_range_df)\n",
        "        sentiment_map.append({'timestamp': end, 'sentiment':avg_val})\n",
        "\n",
        "final_df = pd.DataFrame(sentiment_map)\n",
        "final_df.to_csv('/content/drive/My Drive/CA683/tweet_2009_2018_sentiment.csv', sep=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6UadZ2WS0ze",
        "outputId": "256fb091-63b5-488a-a8ef-5cb4ca409f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing for year 2009\n",
            "Processing for year 2010\n",
            "Processing for year 2011\n",
            "Processing for year 2012\n",
            "Processing for year 2013\n",
            "Processing for year 2014\n",
            "Processing for year 2015\n",
            "Processing for year 2016\n",
            "Processing for year 2017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing for year 2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_09_18 = pd.read_csv('/content/drive/My Drive/CA683/tweet_2009_2018_sentiment.csv')\n",
        "df_19 = pd.read_csv('/content/drive/My Drive/CA683/tweet_2019_sentiment.csv')"
      ],
      "metadata": {
        "id": "Iow_RiPAT7WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df_09_18, df_19]\n",
        "result = pd.concat(\n",
        "    frames,\n",
        "    axis=0,\n",
        "    join=\"outer\",\n",
        "    ignore_index=True,\n",
        "    keys=None,\n",
        "    levels=None,\n",
        "    names=None,\n",
        "    verify_integrity=False,\n",
        "    copy=True,\n",
        ")\n",
        "result.to_csv('/content/drive/My Drive/CA683/tweet_final_sentiment.csv', sep=',')"
      ],
      "metadata": {
        "id": "YQTDDKFyjUxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}